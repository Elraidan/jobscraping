from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd

# Initialize the WebDriver for Firefox
browser = webdriver.Firefox()  # This initializes the browser correctly

# URL for Jobly IT job listings
url = 'https://fi.indeed.com/jobs?q=IT&l=&from=searchOnHP&vjk=419e2e658d386fea'

# Open the webpage with Selenium
browser.get(url)  # Use browser instead of driver

# Wait for the page to load fully (adjust time as needed)
browser.implicitly_wait(10)  # Implicit wait for elements to be loaded

# Parse the page source with BeautifulSoup
soup = BeautifulSoup(browser.page_source, 'html.parser')

# Find all the job listings (div with class 'job__item')
job_listings = soup.find_all('div', class_='job__item')

# List to store job data
job_data = []

# Loop through all job listings and extract the relevant details
for job in job_listings:
    # Extract job title from <a> tag inside the job listing
    job_title_tag = job.find('a', class_='job__title')
    job_title = job_title_tag.text.strip() if job_title_tag else 'Job title not available'

    # Extract company name
    company_name_tag = job.find('div', class_='job__company')
    company_name = company_name_tag.text.strip() if company_name_tag else 'Company name not available'

    # Extract job location
    location_tag = job.find('div', class_='job__location')
    location = location_tag.text.strip() if location_tag else 'Location not available'

    # Extract post date
    post_date_tag = job.find('span', class_='job__date')
    post_date = post_date_tag.text.strip() if post_date_tag else 'Post date not available'

    # Extract company logo URL (if available)
    logo_image_tag = job.find('img', class_='job__logo')
    logo_image_url = logo_image_tag['src'] if logo_image_tag else 'Logo not available'

    # Append the job details to the list
    job_data.append({
        'Job Title': Job_Title,
        'Post Date': post_date,
        'Company Name': company_name,
        'Location': location,
        'Company Logo URL': logo_image_url
    })

# Convert the list of job data to a Pandas DataFrame
df = pd.DataFrame(job_data)

# Check if any job data was extracted
if df.empty:
    print("No job listings found.")
else:
    # Save the data to an Excel file
    output_file = r'C:\Users\Niklas\Documents\Python\job_scraper.xlsx'  # Use raw string for file path
    df.to_excel(output_file, index=False)
    print(f"Data has been saved to {output_file}")


